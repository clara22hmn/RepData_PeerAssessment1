find_rtools()
find_Rtools()
find_rtools()
find_rtools()
library(devtools)
find_rtools()
install.packages("metafor")
??escalc
install.packages(KernSmooth)
install.packages("KernSmooth")
?copyright
copyright("KernSmooth")
library(KernSmooth)
?gl
library(datasets)
data(iris)
?iris
head(iris)
colMeans(iris$Sepal.Length)
colMeans(iris)
mean(iris)
mean(iris$Sepal.Length)
apply(iris[,1:4],2,mean)
data(mtcars)
head(mtcars)
?with
with(mtcars, tapply(mpg, cyl, mean))
split(mtcars, mtcars$cyl)
sapply(split(mtcars, mtcars$cyl), mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429-82.63636
debug(ls)
ls
debug(ls)
ls()
head(iris)
q
head(iris)
library(datasets)
data("iris")
head(iris)
mean(iris$Sepal.Length[which(iris$Species=="virginica")])
data(mtcars)
head(mtcars)
tapply(mtcars$hp, mtcars$cyl, mean)
209.21429 -82.63636
set.seed(1)
?rpois
rpois(5,2)
?rep
set.seed(10)
x<-rep(0:1, each=5)
x
e<-rnorm(10,0,20)
e
?rnorm
?rbinom
install.packages(c("car", "chron", "coda", "colorspace", "git2r", "Hmisc", "logistf", "rmarkdown", "RSQLite", "zoo"))
library(xlsx)
install.packages("rJava")
library(xlsx)
qnorm(0.95, 1100, 75)
qnorm(0.95, 1100, 75/10)
?pbinom
pbinom(4,5,0.5)
pbinom(4,5,0.5,lower.tail = F)
0.5^5
5*0.5^5
ppois
?ppois
dpois(10,15)
dbinom(4,5,0.5)
dbinom(c(4,5),5,0.5)
pbinom(4,5,0.5)
1-pbinom(3,5,0.5)
ppois(10,15)
?dt
qt(0.975, 8)
1100+c(-1,1)*qt(0.975,8)*30
2/qt(0.975,8)
1100+c(-1,1)*qt(0.975,8)*30/sqrt(9)
2/qt(0.975,8)*3
?t.test
(9*0.6+9*0.68)/18
3-5+c(-1,1)*qt(0.975,18)*0.64*sqrt(1/10+1/10)
3-5+c(-1,1)*qt(0.975,18)*sqrt(0.64)*sqrt(1/10+1/10)
6-4+c(-1,1)*qnorm(0.975)*sqrt(0.5/100+2/100)
qnorm(0.975)
qnorm(0.95)
6-4+c(-1,1)*qnorm(0.95)*sqrt(0.5/100+2/100)
(8*1.5+8*1.8)/16
-3-1+c(-1,1)*qt(0.95,16)*sqrt(1.65)*sqrt(1/9+1/9)
-3-1+c(-1,1)*qt(0.95,16)*sqrt((1.5^2*8+1.8^2*8)/16)*sqrt(1/9+1/9)
bl<-c(140,138,150,148,135)
wk2<-c(132,135,151,146,130)
?t.test
dif<-wk2-bl
t.test(dif,alternative = "two.sided",mu=0,paired = T)
t.test(bl,wk2,alternative = "two.sided",mu=0,paired = T)
1100+c(-1,1)*30/3*qt(0.975,8)
pbinom
pbinom(0,4,0.5)
pbinom(1,4,0.5)
qbinom(1,4,0.5)
dbinom(3,4,0.5)
dbinom(3,4,0.5,lower.tail=F)
?dbionom
?dbinom
pbinom(3,4,0.5)
pbinom(4,4,0.5)
pbinom(2,4,0.5,lower.tail = F)
?ppois
ppois(10/1787, 1/100, lower.tail = F)
dpois(10/1787, 1/100, lower.tail = F)
qpois(10/1787, 1/100, lower.tail = F)
dpois(10/1787, 1/100, lower.tail = F)
ppois(10/1787, 1/100, lower.tail = F)
ppois((10/1787), 0.01, lower.tail = F)
10/1787
dpois(10/1787, 1/100)
poisson.test(10, T=1787, r=17.87, alternative="less")
poisson.test(10, T=1787, r=17.87, alternative="greater")
?ppois
ppois(10/1787,0.01,)
ppois(10/1787,0.01)
dpois(10, 17.87)
dpois(c(1:10), 17.87)
sum(dpois(c(1:10), 17.87))
-4/(sqrt(1.5^2*8+1.8^2*8)*sqrt(1/9+1/9))
?qt
-4/(sqrt((1.5^2*8+1.8^2*8)/16)*sqrt(1/9+1/9))
qt(-5.121475,16)
qt(-1.6,16)
qt(1.6,16)
?qt
qt
pt(-5.121475, 16)
power.t.test
?power.t.test
power.t.test(n=100,delta=0,sd=0.04,sig.level=0.05,type="one.sample",alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04,sig.level=0.05,type="one.sample",alternative="one.sided")
power.t.test(delta=0.01,sd=0.04,sig.level=0.05,power=0.9,type="one.sample",alternative="one.sided")
rexp(lambda=0.2)
rexp(0.2)
rexp(40, 0.2)
?rexp
knitr::opts_chunk$set(echo = TRUE)
nsim <- 1000
lambda <- 0.2
n <- 40
hist(n,lambda)
hist(rexp(n,lambda))
dat <- NULL
for (i in 1:nsim) {dat <- cbind(dat, rexp(n,lambda))}
sample.mean <- apply(dat, 2, mean)
hist(sample.mean)
?hist
?var
var(sample.mean)
5^2/40
?dnorm
hist(sample.mean)
curve(dnorm(x, mean=1/lambda, sd=1/lambda), col="darkblue", lwd=2, add=TRUE)
dnorm(x, mean=1/lambda, sd=1/lambda)
plot(dnorm(x, mean=1/lambda, sd=1/lambda))
hist(sample.mean)
curve(dnorm(x, mean=1/lambda, sd=1/lambda), col="darkblue", lwd=2, add=TRUE)
set.seed(20170104)
dat <- NULL
for (i in 1:nsim) {dat <- cbind(dat, rexp(n,lambda))}
View(dat)
sample.mean <- apply(dat, 2, mean)
hist(sample.mean)
curve(dnorm(x, mean=1/lambda, sd=1/lambda), col="darkblue", lwd=2, add=TRUE)
var(sample.mean)
hist(sample.mean, freq=F)
curve(dnorm(x, mean=1/lambda, sd=1/lambda), col="darkblue", lwd=2, add=TRUE)
hist(sample.mean, freq=F)
hist(sample.mean, freq=F)
curve(dnorm(x, mean=1/lambda, sd=1/lambda), col="darkblue", lwd=2, add=TRUE)
?dnorm
hist(sample.mean, freq=F)
curve(dnorm, add=T, mean=1/lambda, sd=1/lambda)
curve(dnorm(x, mean=(1/lambda), sd=(1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
)
hist(sample.mean, freq=F)
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
?hist
hist(sample.mean, freq=F, xlim=c(0,0.5))
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
dnorm(5, mean=1/lambda, sd=1/lambda/sqrt(n))
hist(sample.mean, freq=F, ylim=c(0,0.6))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col=2, add=TRUE)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col=1, add=TRUE)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col=3, add=TRUE)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col=3, add=TRUE)
col
col(3)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
abline(v=1/lambda)
abline(v=1/lambda, col="darkgreen", lwd=2)
?abline
abline(v=1/lambda, lty=2, col="darkgreen", lwd=2)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
abline(v=1/lambda, lty=2, col="darkgreen", lwd=2)
hist(sample.mean, freq=F, ylim=c(0,0.5))
curve(dnorm(x, mean=1/lambda, sd=1/lambda/sqrt(n)), col="darkblue", lwd=2, add=TRUE)
abline(v=1/lambda, lty=2, col=2, lwd=2)
1/lambda/sqrt(40)
var(sample.mean) # Theoretical variance = 1/lambda/sqrt(40) =
nsim <- 1000
n <- 40
lambda <- 0.2
set.seed(2017)
dat <- NULL
for (i in 1:nsim) {dat <- cbind(dat, rexp(n,lambda))}
sample.mean <- apply(dat, 2, mean)
mean(sample.mean) # Theoretical mean = 1/lambda = 5
var(sample.mean) # Theoretical variance = 1/lambda/sqrt(n) =
1/lambda/sqrt(n)
rm(list=ls())
?MySQL
??MySQL
install.packages("RMySQL")
??MySQL
ucscDB <-dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
install.packages("lattice")
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data=airquality)
airquality <- transform(airquality, Month=factor(Month))
xyplot(Ozone ~ Wind | Month, data=airquality, layout=c(5,1))
p <- xyplot(Ozone ~ Wind, data=airquality)
p
?gl
library(ggplot2)
getwd()
rm(p)
str(mpg)
?str
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, color=drv, geom=c("point","smooth"))
qplot(displ, hwy, data=mpg, geom=c("point","smooth"))
qplot(hwy, data=mpg, fill=drv)
qplot(hwy, data=mpg)
qplot(displ, hwy, data=mpg, facets=.~drv)
qplot(hwy, data=mpg, facets=.~drv)
qplot(hwy, data=mpg, facets=drv~.,)
qplot(hwy, data=mpg, facets=drv~.,binwidth=2)
str(maacs)
g <- ggplot(mpg, aes(hwy, displ))
summary(g)
p <- g + geom_point()
p
g + geom_point()
g + geom_point() + geom_smooth()
g + geom_point() + geom_smooth(method="lm")
table(mpg$hwy)
g + geom_point() + geom_smooth(method="lm") + facet_grid(.~drv)
g + geom_point(aes(color=drv))
g + geom_point(aes(color=drv), size=4)
g + geom_point(aes(color=drv), size=2)
g + geom_point(aes(color=drv), size=2, alpha=1/2)
g + geom_point(color=2, size=2, alpha=1/2)
g + geom_point(color="darkgreen", size=2, alpha=1/2)
?theme_bw
?coord_cartesian
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?xyplot
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(votes, rating, data = movies) + geom_smooth()
installed.packages("knitr")
install.packages("slidify")
ï¼Ÿdata
?data
?pairs
install.packages("xtable")
install.packages("grDevices")
install.packages("grDevices")
install.packages(c("backports", "htmlTable", "TH.data"))
??colorRamp
colorRamp(c("red","blue"))
pal<-colorRamp(c("red","blue"))
pal(0.3)
install.packages("RColorBrewer")
?brewer.pal
??brewer.pal
??colorRampPalette
setwd("C:/Users/MHuang/Google Drive/Coursera/Data Science Specialization_JHU/Reproducible Research/RepData_PeerAssessment1")
rm(list=ls())
dat <- read.csv("activity.csv", header=T)
head(dat)
table(date)
table(dat$date)
?Date
?as.Date
?sum
?tapply
total <- tapply(dat$steps, dat$date, FUN=sum)
total <- tapply(dat$steps, dat$date, FUN=sum(..., na.rm=TRUE))
total <- tapply(dat$steps, dat$date, FUN=sum(na.rm=TRUE))
sum(dat$steps, data=dat$[dat$date=="2012-10-01",])
sum(dat$steps, data=dat$[which(dat$date=="2012-10-01"),])
sum(dat$steps, data=dat[which(dat$date=="2012-10-01"),])
sum(dat$steps, data=dat[which(dat$date=="2012-10-01"),], na.rm=TRUE)
sum(dat$steps, data=dat[which(dat$date=="2012-10-02"),])
sum(dat$steps, data=dat[which(dat$date=="2012-10-02"),na.rm=T])
sum(dat$steps, data=dat[which(dat$date=="2012-10-02"),])
sum(dat$steps, data=dat[which(dat$date=="2012-10-02"),], na.rm=TRUE)
sum(dat$steps, data=dat[which(dat$date=="2012-10-02"),])
total
hist(total)
mean(total)
median(total)
mean(total,na.rm = T)
median(total, na.rm=T)
summary(total)
View(dat)
rm(total)
avg.per.int <- tapply(dat$steps, dat$interval, FUN=mean)
avg.per.int
?tapply
avg.per.int <- tapply(dat$steps, dat$interval, FUN=mean, na.rm=T)
total.per.day <- tapply(dat$steps, dat$date, FUN=sum, na.rm=T)
knitr::opts_chunk$set(echo = TRUE)
hist(total.per.day)
summary(total.per.day)
plot(avg.per.int, dat$interval, lty="l")
plot(avg.per.int, dat$interval, lty="l", na.rm=T)
plot(unique(dat$interval), avg.per.int, lty="l")
plot(unique(dat$interval), avg.per.int, type="l")
dat.int <- as.data.frame(cbind(avg.per.int, unique(dat$interval)))
colnames(dat.int) <- c("avg.per.int", "interval")
dat.int$interval[which.max(dat.int$avg.per.int)]
dat.int$interval[which.max(dat.int$avg.per.int)]/12
dat.int$interval[which.max(dat.int$avg.per.int)]/60
5/60
5%%60
dat.int$interval[which.max(dat.int$avg.per.int)]
dat.int$interval[which.max(dat.int$avg.per.int)]%/%60
dat.int$interval[which.max(dat.int$avg.per.int)]%%60
which(is.na(dat$steps))
sum(which(is.na(dat$steps)))
table(is.na(dat$steps))
as.Date(dat$date, "%Y-%M-%D")[1:5]
?as.Date
as.Date(dat$date, "%y-%m-%d")[1:5]
as.Date(dat$date, format="%y-%m-%d")[1:5]
class(dat$date)
as.Date(dat$date, format="%Y-%m-%d")[1:5]
dat$date <- as.Date(dat$date, format="%Y-%m-%d")
total.per.day <- tapply(dat$steps, dat$date, FUN=sum, na.rm=T)
hist(total.per.day)
summary(total.per.day)
hist(total.per.day, breaks=10)
hist(total.per.day, breaks=20)
length(unique(dat$date))
length(unique(dat$interval))
hist(total.per.day, breaks=20)
summary(total.per.day)
avg.per.int <- tapply(dat$steps, dat$interval, FUN=mean, na.rm=T)
dat.int <- as.data.frame(cbind(avg.per.int, unique(dat$interval)))
colnames(dat.int) <- c("avg.per.int", "interval")
dat.int$interval[which.max(dat.int$avg.per.int)]
dat.int$interval[which.max(dat.int$avg.per.int)]%/%60
dat.int$interval[which.max(dat.int$avg.per.int)]%%60
70%/%60
70%%60
table(is.na(dat$steps))
?data.frame
table(is.na(dat$dates))
table(is.na(dat$date))
table(is.na(dat$interval))
colnames(dat)
dat.imp <- NULL
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp[i,] <- dat[i,]}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
dat.imp[i,1] <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
dat.imp[i,2] <- dat[i,2]
dat.imp[i,3] <- int.tmp
}
}
class(dat.int)
head(dat.int)
int.tmp=0
dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
dat.imp <- matrix(data=NA, nrow=nrow(dat), ncol=ncol(dat))
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp[i,] <- dat[i,]}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
dat.imp[i,1] <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
dat.imp[i,2] <- dat[i,2]
dat.imp[i,3] <- int.tmp
}
}
dat.imp <- NULL
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
dat.imp <- rbind(dat.imp, c(steps.tmp, date.tmp, int.tmp))
}
}
?data.frame
?as.data.frame
dat.imp <- as.data.frame(col.names=colnames(dat))
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer())
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
dat.imp <- rbind(dat.imp, c(steps.tmp, date.tmp, int.tmp))
}
}
head(dat.imp)
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer())
head(dat.imp)
head(as.matrix(dat))
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer(), nrow=nrow(dat), ncol=ncol(dat))
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
record.tmp <- as.data.frame(c(steps.tmp, date.tmp, int.tmp))
colnames(record.tmp) <- colnames(dat)
dat.imp <- rbind(dat.imp, record.tmp)
}
}
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer())
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
record.tmp <- as.data.frame(c(steps.tmp, date.tmp, int.tmp))
colnames(record.tmp) <- colnames(dat)
dat.imp <- rbind(dat.imp, record.tmp)
}
}
i=1
int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
record.tmp <- as.data.frame(c(steps.tmp, date.tmp, int.tmp))
colnames(record.tmp) <- colnames(dat)
dat.imp <- rbind(dat.imp, record.tmp)
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer())
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
record.tmp <- as.data.frame(c(steps.tmp, date.tmp, int.tmp))
dat.imp <- rbind(dat.imp, record.tmp)
}
}
dat.imp <- data.frame(steps=integer(), date=as.Date(character()), interval=integer())
for (i in 1:nrow(dat)) {
if (!is.na(dat[i,1])) {dat.imp <- rbind(dat.imp, dat[i,])}
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
steps.tmp <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
date.tmp <- dat[i,2]
record.tmp <- c(steps.tmp, date.tmp, int.tmp)
dat.imp <- rbind(dat.imp, record.tmp)
}
}
?skip
??skip
dat.imp <- dat
for (i in 1:nrow(dat.imp)) {
if (is.na(dat[i,1])) {int.tmp <- dat$interval[i]
dat.imp[i,1] <- dat.int$avg.per.int[which(dat.int$interval==int.tmp)]
}
}
class(dat.imp)
colnames(dat.imp)
total.per.day.imp <- tapply(dat.imp$steps, dat.imp$date, FUN=sum, na.rm=T)
hist(total.per.day.imp, breaks=20)
hist(total.per.day.imp, breaks=20)
summary(total.per.day.imp)
hist(total.per.day.imp, breaks=20)
hist(total.per.day, breaks=20)
summary(total.per.day)
weekdays <- weekdays(dat.imp$date)
dat.imp$weekday <- 1
dat.imp$weekday[!(weekdays %in% c("Saturday","Sunday"))] <- 0
dat.imp$weekend <- 0
dat.imp$weekend[(weekdays %in% c("Saturday","Sunday"))] <- 1
table(dat.imp$weekday, dat.imp$weekend)
!(weekdays %in% c("Saturday","Sunday"))[1:5]
??ggplot
